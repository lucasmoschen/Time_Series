---
title: "Análise de intervenção e previsão de atividade econômica"
author: 
- Lucas Emanuel Resck Domingues^[Escola de Matemática Aplicada]
- Lucas Machado Moschen^[Escola de Matemática Aplicada]
output:
  pdf_document: default
---

```{r, echo=FALSE, warning=FALSE, message=FALSE}
library(ggplot2)
library(forecast)
library(TSA)
library(tseries)
```

# TODO

(DONE) 1. Fazer o processo de identificação manualmente para obter a primeira opção de modelo (mostrar que aprendemos isso).

(DONE) 2. Usar auto.arima para um segundo modelo. Se eles forem diferentes (o drift faz variar), comparamos os modelos usando checkresiduals. Escolher o "melhor modelo"

(DONE) 3. Fazer previsões do modelo e comparar com pósintervenção. Vamos comparar com a realidade e verificar que de fato houve efeito. 

4. Fitar o modelo em todos os dados: propor um modelo para a crise (talvez dois e repetir a escolha do melhor?)

5. Fazemos as previsões e avaliamos o modelo no teste (podemos comparar com um naive). 

Obs.: Esses 5 passos combrem a Metodologia, mas podemos adicionar algumas cerejas para deixar mais rico, dependendo do tempo. 




# Dados

A série temporal é o total de vendas mensais nos negócios em milhões de dólares, obtido em [Fred, Federal Reserve Bank of St. Louis](https://fred.stlouisfed.org/series/TOTBUSSMNSA). A janela de observações será entre Janeiro de 2002 a Dezembro de 2014, em que os últimos dois anos são utilizados para a validação do modelo de previsão. 

```{r, echo=F}
tbs <- read.csv("data/TOTBUSSMNSA.csv")
tbs <- ts(tbs$TOTBUSSMNSA, start = c(1992, 1), end = c(2020, 9), frequency = 12)
tbs <- window(tbs, start = c(2002, 1), end = c(2014, 12))

autoplot(tbs, main = "Total de vendas nos negócios", 
              xlab = "Tempo", 
              ylab = "Milhões de dólares") + 
  geom_vline(xintercept = (2008 + 7/12), 
             color = 'red', 
             linetype = "dashed", 
             size = 1) + 
  annotate(geom="text", x=2008, y=750000, label="Crise",
              color="red")
```

Vamos separar os últimos dois anos para validação do modelo e portanto, não usaremos no treinamento do modelo. 

```{r, echo=FALSE}
tbs_train <- window(tbs, start = c(2002, 1), end = c(2012,12))
tbs_test <- window(tbs, start = c(2013,1), end = c(2014,12))
```

Vamos considerar que houve uma intervenção (a crise sub-prime) em julho de 2008. 

# 1. Modelagem pré-intervenção 

Antes vamos fazer a modelagem do processo antes da crise. Assim, poderemos verificar que de fato houve efeito pós intervenção. 

```{r, echo=F}
pre_intervention <- window(tbs_train, start = c(2002,1), end = c(2008,6))
pos_intervention <- window(tbs_train, start = c(2008,7), end = c(2012,12))
```

## 1. Modelagem manual Box-Jenkins 

Para isso, vamos seguir a metodologia Box-Jenkins. Primeiro, faremos uma transformação Box-Cox na série, se utilizando do $\lambda$ que minimiza o coeficiente de variação para subséries da série. 

```{r, echo=F}
lambda <- BoxCox.lambda(pre_intervention)
pre_intervention.bc <- BoxCox(pre_intervention, lambda)
print(paste("Obtemos lambda = ", lambda))
```

Agora, vamos remover a tendência diferenciando a série. 

```{r, echo=F}
pre_intervention.d = diff(pre_intervention.bc)
autoplot(pre_intervention.d, main = "Diferença mensal de vendas nos negócios", 
              xlab = "Tempo", 
              ylab = "Milhões de dólares")
```

Com a série diferenciada, vamos checar a sazonalidade anual, como sugerido: 

```{r, echo=F}
kruskal.test(pre_intervention.d,g = cycle(pre_intervention.d))
```

Como o p-valor é pequeno, temos evidência para rejeitar a hipótese nula do teste, o que nos dá suporte para diferenciar a série sazonalmente. Após a diferenciação, podemos ver que a ACF e a PACF não apresentam picos nos lags múltiplos de 12. 

```{r, echo=F}
pre_intervention.ds <- diff(pre_intervention.d, 12)
ggtsdisplay(pre_intervention.ds)
```

Assim, com o teste ADF rejeirando a não estacionaridade, podemos partir para identificar o modelo. 

```{r, echo=F}
adf.test(pre_intervention.bc)
```

Vemos uma ACF decaindo exponencialmente e uma PACF morrendo após o lag 2. Assim imaginamos um modelo AR com grau não maior do que 3. Vamos testar essa ideia com os critérios de informação. Além disso, não percebemos nenhum LAG significativo sazonal, o que pode indicar um MA(1) ou não ter componentes autorregressivos ou de média móvel sazonais. Vamos testar esses modelos também com os critérios de informação. O modelo de teste ARIMA(3,1,3) teve problema de estacionariedade e foi retirado da análise. 

```{r, echo = F}
ARMA.res <- data.frame()
## valor máximo de p,q.
K <- 3
L <- 2
for (p in 0:K) {
    for (q in 0:L) {
        model1 <- Arima(y = pre_intervention.bc, order = c(p, 1, q), seasonal = c(0,1,0))
        model2 <- Arima(y = pre_intervention.bc, order = c(p, 1, q), seasonal = c(0,1,1))
        ARMA.res <- rbind(ARMA.res, c(p,q,model1$aic, model1$bic, model1$aicc,
                                          model2$aic, model2$bic, model2$aicc))
    }
}
names(ARMA.res) = c('p', 'q','AIC', 'BIC', 'AICc', 'AIC (S)', 'BIC (S)', 'AICc (S)')
```

Podemos observar que sem sazonalidade, o melhor modelo segundo os três critérios de informação foi ARMA(2,0) como já tínhamos imaginado. Considerando a sazonalidade, o melhor modelo fica, ao todo 

ARIMA(2,1,0)(0,1,1)[12]

```{r, echo=F}
print(ARMA.res)
```

Agora que já identificamos o modelo, podemos estimá-lo. 

```{r, echo=FALSE}
model1 <- Arima(pre_intervention, 
                order = c(2,1,0), 
                seasonal = c(0,1,1),
                lambda = "auto")
summary(model1)
```

Agora com o modelo treinado, podemos fazer uma checagem sobre os resíduos: 

```{r}
checkresiduals(model1)
jarque.bera.test(model1$residuals)
```

Observamos que existe um resíduo bem deslocado que no ano de 2003 quando houve uma queda que o modelo não conseguiu capturar. Além disso, não aparenta uma normalidade, inclusive tendo-a rejeitada pelo teste Jarque-Bera. Por fim, as correlações estão bem interessantes, dentro das margens e, o teste de Ljung-Box não rejeitou a hipótese de descorrelação. Isso é um bom indício, porém a não normalidade dos dados indica algum problema.  

## 2. Modelo auto.arima 

Vamos averiguar uma segunda opção de modelo que pode ser encontrada automaticamente, utilizando a função `auto.arima`. Assim, vemos que o modelo estimado tem drift e é do tipo 

ARIMA(3,0,0)(2,1,0)[12]. 

```{r, echo=FALSE}
model2 <- auto.arima(pre_intervention, 
           lambda = "auto")
summary(model2)
```

```{r, echo=F}
checkresiduals(model2)
jarque.bera.test(model2$residuals)
```

Pela ACF, os erros certamente tem correlação, a princípio uma correlação autorregressiva, e também existe uma assimetria no histograma. Esses fatos são confirmados com os testes, dado que rejeitamos amabas as hipóteses nulas, isto é, temos evidência para assegurar que não há normalidade e existe correlação nos resíduos. As medidas dos erros de treinamento também não são melhores do que o modelo 1. 

## 3. Modelo auto.arima com variação 

Fazendo algumas experimentações com o `auto.arima` podemos chegar num fato interessante colocando $\lambda = 0$.

```{r, echo=FALSE}
model3 <- auto.arima(pre_intervention, 
                     lambda = 0)
summary(model3)
```

Conseguimos um modelo com todas as medidas de erro menores e, além disso 

```{r, echo=F}
checkresiduals(model3)
jarque.bera.test(model3$residuals)
```

Note que os resíduos aparentam muito mais uma normalidade do que antes, o que também é indicado pelo teste Jarque Bera. Porém o teste Ljung-Box rejeita a hipótese nula, o que mostra que ainda existe uma correlação nos resíduos. 

## 4. Modelo manual com variação 

Utilizando o modelo inicial com a variação de $\lambda$, temos: 

```{r, echo=FALSE}
model4 <- Arima(pre_intervention, 
                order = c(2,1,0), 
                seasonal = c(0,1,1),
                lambda = 0)
summary(model4)
checkresiduals(model4)
jarque.bera.test(model4$residuals)
```

Temos resíduos com uma cara de normalidade e a ACF dentro das faixas de confiança, indicando um processo descorrelacionado. Tanto Jarque Bera quando Ljung Box não rejeitam suas hipóreses nulas, o que nos dá evidência para confirmar que os resíduos formam algo similar a um ruído branco. Os erros de treino também aparentam estar bem em relação ao modelo inicial. 

Desta forma, fica claro que o modelo 4 é o mais indicado para representar a série antes da intervenção. 

# Previsões do modelo e comparação pós intervenção 

```{r, echo=FALSE}
autoplot(tbs, main = "Total de vendas nos negócios", 
              xlab = "Tempo", 
              ylab = "Milhões de dólares") + 
  autolayer(forecast(model4, h = 78)) + 
  geom_vline(xintercept = (2008 + 7/12), 
             color = 'red', 
             linetype = "dashed", 
             size = 1) + 
  annotate(geom="text", x=2008, y=750000, label="Crise",
              color="red")
```


Observamos graficamente que as previsões de nosso modelo ficam em um patamar mais alto do que os dados reais e por isso tomamos como hipótese de que a crise foi significante. Consideramos os procedimentos sugeridos por Box e Tiao (1976) com a checagem do erro de previsão. 

Seja a estatística 
$$
Q = \sum_{j=1}^m a_j^2/\hat{\sigma}_a^2
$$
onde $a_j = Z_j - \hat{Z}_{j-1}(1), j = 1, ..., m$. Sabemos que $Q$ seque uma distribuição $\chi^2(m)$ quando $m$ é grande. 

```{r, echo=F}
n = length(pre_intervention)
m = length(pos_intervention)
a <- rep(0, m)
for (j in 1:m) {
  w <- ts(tbs_train[1:(n+j-1)], start = c(2002,1), frequency = 12)
  model <- Arima(w, order = c(2,1,0), 
                 seasonal = c(0,1,1),
                 lambda = 0)
  z_hat_j <- forecast(model, h = 1)$mean
  a[j] <- pos_intervention[j] - z_hat_j
  if(j==1){
    sigma2 <- model$sigma2
  }
}
Q <- sum(a^2)/sigma2
print(paste("Q = ", Q))
```

Temos que o valor de $Q$ é suficientemente alto para que vejamos que de fato há efeito da crise sub-prime. 

Podemos, então, partir para a modelagem da intervenção. 

# Modelagem com intervenção 

Consideraremos o modelo de intervenção dado por uma série que muda de nível abruptamente, dado a quebra do sistema bancário que tem efeito rápido e com um decaímento do efeito exponencial, dado que a economia se autoregula. Suporemos que não hajam outras intervenções, como governamental, e elas devem ser incorporadas no modelo. Seja ele:

$$
u_t = \begin{cases}
0, t < \text{julho 2018} \\
\delta^k \omega_0, t = \text{julho 2008} + k, k = 0, 1, 2, ...
\end{cases}
$$
Estimaremos em toda série esses parâmetros também ($\delta$ e $\omega_0$). 

```{r, echo=F}
tbs_train.bc <- BoxCox(tbs_train, lambda = 0)
mod.arimax <- arimax(tbs_train.bc, 
                     order = c(2, 1, 0),
                     seasonal = c(0, 1, 1),
                     xtransf=data.frame(Crise=1*(seq(tbs_train)==(length(pre_intervention) + 1))),
                     transfer=list(c(1, 1)),
                     method = "ML") # problemas com CSS-ML e CSS, porquê? 
summary(mod.arimax)
```

Vamos ver como se comportam os resíduos do modelo. 

```{r, echo=F, warning=F}
par(mfrow = c(2,1))
ggtsdisplay(mod.arimax$residuals)
```

A ACF dos resíduos e a PACF estão com picos, o que indica que ainda existe uma correlação não capturada. Vamos ver como o modelo fitado se compara com os dados reais na escala log, dada a transformação BoxCox com $\lambda = 0$ que fizemos. 

```{r, echo = F, warning = F, message=F}
library(ggfortify)
autoplot(mod.arimax,
         ts.geom = "point", 
         fitted.colour = "blue", 
         main = "Comparação dos dados reais com o modelo") + 
  ylab('Valores log') + xlab('Tempo') 
```

