---
title: "Prediction of ozone level in Boston"
author: 
- Lucas Emanuel Resck Domingues
- Lucas Machado Moscheb^[Escola de Matem√°tica Aplicada]
output:
  pdf_document: default
  html_notebook: default
---

# Predicting O3 in Boston

```{r echo = F, warning = F, message=F}
library(zoo)
library(dplyr)
library(forecast)
library(tseries)
library(bnstruct)
```


## Load and visualize

```{r, echo = F}
bos = read.csv("data/BOS.csv")
plot(bos$Date.Local, bos$O3.Mean, main = 'Daily average level of O3 in Boston', 
                                  xlab = 'Date', ylab = 'Kg/m3')
```

## Data treatment

We noticed that some days do not exist in the dataset, for example, the day August 31, 2001 does not have information in the dataset. 

```{r, echo = F}
bos[148:153,]
```

Also, there is duplicated days, as June 9, 2002: 

```{r, echo=F}
day <- as.Date(bos$Date.Local[duplicated(bos$Date.Local)])
bos[bos$Date.Local %in% c(toString(day - 1), toString(day), toString(day + 1)),]
```

The duplicated one is easier to deal, but the nan values are harder. First we calculate the mean value between the duplicated. 

```{r, echo = F}
bos[413, "O3.Mean"] = mean(bos[bos$Date.Local == toString(day),]$O3.Mean)
bos <- distinct(bos, Date.Local, .keep_all = TRUE)
```

The rate of NA values is almost 5% of the dataset. 

```{r, echo = F}
o3 <- zooreg(bos$O3.Mean, order.by = as.Date(as.character(bos$Date.Local), format = "%Y-%m-%d"))
o3.ts <- as.ts(o3)

print(sum(is.na(o3.ts))/length(o3.ts))
```

So as to solve that problem, we make a knn imputation using the month ($k = 30$)

```{r}
o3.clean <- knn.impute(as.matrix(o3.ts), k = 30)
o3.clean <- as.ts(o3.clean)
plot(o3.clean, main = 'Daily average level of O3 in Boston (after imputation)', 
                xlab = 'Date', ylab = 'Kg/m3')
```


```{r, echo= F}
o3_train = o3.clean[1:(length(o3)[1] - 365),]
o3_test = o3.clean[(length(o3)[1] - 365 + 1):length(o3)[1],]
```

## Models: case 1 

Now we develop some models using the train data.

The metric to compare is the Mean Absolute Error (MAE) in the predictions: 

```{r}
mae <- function(ytrue, ypred)
{
    return(mean(abs(ytrue - ypred)))
}
```

We will use `rollyapply` in order to calculate the error, considering the last two years to predict one week forward. 

### Decompose

First of all we make a seasonality test using Kruskal-Wallis. Actually it tests whether samples originate from the same distribution. We can organize it to be samples for each corresponding day. We compare two different frequencies: monthly and yearly. The second one showed the smallest p-value, in particular less than 0.05. FOr that reason, we will use 365 in the seasonality.  

```{r, echo = F}
n <- length(o3_train)
t <- seq(1,n)
size <- 2*365 + 7 + 1
```

```{r,echo = F}
freq = 31
g <- rep(c(1:freq), ceiling(n/freq))[1:n]
kruskal.test(o3_train, g = g)
```

```{r,echo = F}
freq = 365
g <- rep(c(1:freq), ceiling(n/freq))[1:n]
kruskal.test(o3_train, g = g)
```

#### Additive model 

First we analyse the MAE. 

```{r, echo=F}
stl_add_model_day <- function(t) {
  model <- stl(ts(o3_train[t[-c((size-6):size)]], frequency = freq), 
               s.window = "periodic", robust = T)
  prediction = forecast(model, h=7)
  return(as.numeric(prediction$mean))
}

prediction = rollapply(t, width = size, stl_add_model_day)
stl_add_mae <- mae(o3_train[size:n], prediction[,7])
stl_add_mae
```

We also can fit the model using `t.window` and analyse the reminder of the method. 

```{r echo=F}
model <- stl(ts(o3_train, frequency = freq), 
             s.window = "periodic", t.window = 2*365 + 1, robust = T)
plot(model)
```

The ACF and the PACF of the reminder: 

```{r, echo = F}
par(mfrow = c(1,2))
acf(model$time.series[,'remainder'], lag.max = size, main = 'ACF Remainder')
pacf(model$time.series[,'remainder'], lag.max = size, main = 'PACF Remainder')
```

We see that there are a big spike when $\text{lag} = 365$. It seems not so good for a reminder. We could fit an ARMA model in this reminder yet. 

#### Multiplicative model 

First we analyse the MAE. 

```{r, echo=F}
data = log(o3_train + 1)
stl_mul_model_day <- function(t) {
  model <- stl(ts(data[t[-c((size-6):size)]], frequency = freq), 
               s.window = "periodic", robust = T)
  prediction = forecast(model, h=7)
  return(as.numeric(prediction$mean))
}

prediction = rollapply(t, width = size, stl_mul_model_day)
stl_mul_mae <- mae(o3_train[size:n], exp(prediction[,7]) - 1)
stl_mul_mae
```

We also can fit the model using `t.window` and analyse the reminder of the method. 

```{r echo=F}
model <- stl(ts(data, frequency = freq), 
             s.window = "periodic", t.window = 2*365 + 1, robust = T)
plot(model)
```

The ACF and the PACF of the reminder: 

```{r, echo = F}
par(mfrow = c(1,2))
acf(model$time.series[,'remainder'], lag.max = size, main = 'ACF Remainder')
pacf(model$time.series[,'remainder'], lag.max = size, main = 'PACF Remainder')
```

We see that there are a big spike when $\text{lag} = 365$. It seems not so good for a reminder. We could fit an ARMA model in this reminder yet. The same problem as before. 

### Regression

### Holt-Winters

### ARMA

## Models: case 2 
